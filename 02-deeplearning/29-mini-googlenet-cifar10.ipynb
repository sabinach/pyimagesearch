{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"29-mini-googlenet-cifar10.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1r0bopYnppgrbiyFQ17YIJokHLQILqNG9","authorship_tag":"ABX9TyOS78rRipE2Na6I26WToq8m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qMURSL3Hzd_Z"},"source":["**Use GPU: Runtime -> Change runtime type -> GPU (Hardware Accelerator)**"]},{"cell_type":"markdown","metadata":{"id":"BGWyUyeZzf7h"},"source":["Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTYDkn_qzgU8","executionInfo":{"status":"ok","timestamp":1618902552605,"user_tz":240,"elapsed":740,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"54b9c77a-c319-43c3-9bde-08b1dea5c7c3"},"source":["!cat ~/.keras/keras.json"],"execution_count":1,"outputs":[{"output_type":"stream","text":["{\n","    \"epsilon\": 1e-07, \n","    \"floatx\": \"float32\", \n","    \"image_data_format\": \"channels_last\", \n","    \"backend\": \"tensorflow\"\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szYZM8Bnzjay","executionInfo":{"status":"ok","timestamp":1618902554309,"user_tz":240,"elapsed":2186,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"199e7e19-f9ff-4bde-bc17-65e4c21127da"},"source":["import keras\n","print(keras.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.4.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LpU0-24szkDt"},"source":["Mini-GoogLeNet"]},{"cell_type":"code","metadata":{"id":"bZOY_oYrzjti","executionInfo":{"status":"ok","timestamp":1618902554310,"user_tz":240,"elapsed":1387,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}}},"source":["from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import AveragePooling2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras.layers import Flatten\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import concatenate\n","from keras import backend as K"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYFgJuUtzue5","executionInfo":{"status":"ok","timestamp":1618902554712,"user_tz":240,"elapsed":1238,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}}},"source":["class MiniGoogLeNet:\n","\t@staticmethod\n","\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n","\t\t# define a CONV => BN => RELU pattern\n","\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n","\t\tx = BatchNormalization(axis=chanDim)(x)\n","\t\tx = Activation(\"relu\")(x)\n","\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef inception_module(x, numK1x1, numK3x3, chanDim):\n","\t\t# define two CONV modules, then concatenate across the\n","\t\t# channel dimension\n","\t\tconv_1x1 = MiniGoogLeNet.conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n","\t\tconv_3x3 = MiniGoogLeNet.conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n","\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\n","\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef downsample_module(x, K, chanDim):\n","\t\t# define the CONV module and POOL, then concatenate\n","\t\t# across the channel dimensions\n","\t\tconv_3x3 = MiniGoogLeNet.conv_module(x, K, 3, 3, (2, 2), chanDim, padding=\"valid\")\n","\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\n","\n","\t\t# return the block\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef build(width, height, depth, classes):\n","\t\t# initialize the input shape to be \"channels last\" and the\n","\t\t# channels dimension itself\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# define the model input and first CONV module\n","\t\tinputs = Input(shape=inputShape)\n","\t\tx = MiniGoogLeNet.conv_module(inputs, 96, 3, 3, (1, 1), chanDim)\n","\n","\t\t# two Inception modules followed by a downsample module\n","\t\tx = MiniGoogLeNet.inception_module(x, 32, 32, chanDim)\n","\t\tx = MiniGoogLeNet.inception_module(x, 32, 48, chanDim)\n","\t\tx = MiniGoogLeNet.downsample_module(x, 80, chanDim)\n","\n","\t\t# four Inception modules followed by a downsample module\n","\t\tx = MiniGoogLeNet.inception_module(x, 112, 48, chanDim)\n","\t\tx = MiniGoogLeNet.inception_module(x, 96, 64, chanDim)\n","\t\tx = MiniGoogLeNet.inception_module(x, 80, 80, chanDim)\n","\t\tx = MiniGoogLeNet.inception_module(x, 48, 96, chanDim)\n","\t\tx = MiniGoogLeNet.downsample_module(x, 96, chanDim)\n","\n","\t\t# two Inception modules followed by global POOL and dropout\n","\t\tx = MiniGoogLeNet.inception_module(x, 176, 160, chanDim)\n","\t\tx = MiniGoogLeNet.inception_module(x, 176, 160, chanDim)\n","\t\tx = AveragePooling2D((7, 7))(x)\n","\t\tx = Dropout(0.5)(x)\n","\n","\t\t# softmax classifier\n","\t\tx = Flatten()(x)\n","\t\tx = Dense(classes)(x)\n","\t\tx = Activation(\"softmax\")(x)\n","\n","\t\t# create the model\n","\t\tmodel = Model(inputs, x, name=\"googlenet\")\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0i46Ldz203K-"},"source":["Training Monitor"]},{"cell_type":"code","metadata":{"id":"BeKfYJPW09z2","executionInfo":{"status":"ok","timestamp":1618902556732,"user_tz":240,"elapsed":1080,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}}},"source":["# import the necessary packages\n","from keras.callbacks import BaseLogger\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import json\n","import os\n","\n","class TrainingMonitor(BaseLogger):\n","    def __init__(self, figPath, jsonPath=None, startAt=0):\n","        # store the output path for the figure, the path to the JSON\n","        # serialized file, and the starting epoch\n","        super(TrainingMonitor, self).__init__()\n","        self.figPath = figPath\n","        self.jsonPath = jsonPath\n","        self.startAt = startAt\n","\n","    def on_train_begin(self, logs={}):\n","        # initialize the history dictionary\n","        self.H = {}\n","\n","        # if the JSON history path exists, load the training history\n","        if self.jsonPath is not None:\n","            if os.path.exists(self.jsonPath):\n","                self.H = json.loads(open(self.jsonPath).read())\n","\n","                # check to see if a starting epoch was supplied\n","                if self.startAt > 0:\n","                    # loop over the entries in the history log and\n","                    # trim any entries that are past the starting\n","                    # epoch\n","                    for k in self.H.keys():\n","                        self.H[k] = self.H[k][:self.startAt]\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        # loop over the logs and update the loss, accuracy, etc.\n","        # for the entire training process\n","        for (k, v) in logs.items():\n","            l = self.H.get(k, [])\n","            l.append(float(v))\n","            self.H[k] = l\n","\n","        # check to see if the training history should be serialized\n","        # to file\n","        if self.jsonPath is not None:\n","            f = open(self.jsonPath, \"w\")\n","            f.write(json.dumps(self.H))\n","            f.close()\n","\n","        # ensure at least two epochs have passed before plotting\n","        # (epoch starts at zero)\n","        if len(self.H[\"loss\"]) > 1:\n","            # plot the training loss and accuracy\n","            N = np.arange(0, len(self.H[\"loss\"]))\n","            plt.figure()\n","            plt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n","            plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n","            plt.plot(N, self.H[\"accuracy\"], label=\"train_accuracy\")\n","            plt.plot(N, self.H[\"val_accuracy\"], label=\"val_accuracy\")\n","            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(len(self.H[\"loss\"])))\n","            plt.xlabel(\"Epoch #\")\n","            plt.ylabel(\"Loss/Accuracy\")\n","            plt.legend()\n","\n","            # save the figure\n","            plt.savefig(self.figPath)\n","            plt.close()"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bfft68rtFk5H"},"source":["Learning Rate Scheduler/Decay"]},{"cell_type":"code","metadata":{"id":"UYW_FKzWFmYB","executionInfo":{"status":"ok","timestamp":1618902558316,"user_tz":240,"elapsed":1195,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}}},"source":["# definine the total number of epochs to train for along with the\n","# initial learning rate\n","NUM_EPOCHS = 70\n","INIT_LR = 5e-3\n","\n","def poly_decay(epoch):\n","\t# initialize the maximum number of epochs, base learning rate,\n","\t# and power of the polynomial\n","\tmaxEpochs = NUM_EPOCHS\n","\tbaseLR = INIT_LR\n","\tpower = 1.0\n","\n","\t# compute the new learning rate based on polynomial decay\n","\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n","\n","\t# return the new learning rate\n","\treturn alpha"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LroRcGC11DVT"},"source":["Train GoogLeNet (Cifar10)"]},{"cell_type":"code","metadata":{"id":"iquONSpJHQ0g","executionInfo":{"status":"ok","timestamp":1618902600830,"user_tz":240,"elapsed":1573,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}}},"source":["# import the necessary packages\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import LearningRateScheduler\n","from keras.optimizers import SGD\n","from keras.datasets import cifar10\n","import numpy as np\n","import os"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"qe07Nb7T1Fny","executionInfo":{"status":"ok","timestamp":1618902600831,"user_tz":240,"elapsed":1270,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}}},"source":["def train_googlenet_cifar10(model_filepath, output_filepath):\n","    # load the training and testing data, converting the images from\n","    # integers to floats\n","    print(\"[INFO] loading CIFAR-10 data...\")\n","    ((trainX, trainY), (testX, testY)) = cifar10.load_data()\n","    trainX = trainX.astype(\"float\")\n","    testX = testX.astype(\"float\")\n","\n","    # apply mean subtraction to the data\n","    mean = np.mean(trainX, axis=0)\n","    trainX -= mean\n","    testX -= mean\n","\n","    # convert the labels from integers to vectors\n","    lb = LabelBinarizer()\n","    trainY = lb.fit_transform(trainY)\n","    testY = lb.transform(testY)\n","\n","    # construct the image generator for data augmentation\n","    aug = ImageDataGenerator(width_shift_range=0.1,\n","        height_shift_range=0.1, horizontal_flip=True,\n","        fill_mode=\"nearest\")\n","\n","    # construct the set of callbacks\n","    figPath = os.path.sep.join([output_filepath, \"{}.png\".format(os.getpid())])\n","    jsonPath = os.path.sep.join([output_filepath, \"{}.json\".format(os.getpid())])\n","    callbacks = [TrainingMonitor(figPath, jsonPath=jsonPath),LearningRateScheduler(poly_decay)]\n","\n","    # initialize the optimizer and model\n","    print(\"[INFO] compiling model...\")\n","    opt = SGD(lr=INIT_LR, momentum=0.9)\n","    model = MiniGoogLeNet.build(width=32, height=32, depth=3, classes=10)\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","\n","    # train the network\n","    print(\"[INFO] training network...\")\n","    model.fit_generator(aug.flow(trainX, trainY, batch_size=64),\n","        validation_data=(testX, testY), steps_per_epoch=len(trainX) // 64,\n","        epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1)\n","\n","    # save the network to disk\n","    print(\"[INFO] serializing network...\")\n","    model.save(model_filepath)\n","    print(\"[INFO] done.\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvFFJUX9F5Gq","executionInfo":{"status":"ok","timestamp":1618904809421,"user_tz":240,"elapsed":2209256,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"512eb920-a588-413c-c9b9-6728c472081f"},"source":["train_googlenet_cifar10(model_filepath=\"drive/MyDrive/pyimagesearch/output/29-mini-googlenet/minigooglenet_cifar10.hdf5\", output_filepath=\"drive/MyDrive/pyimagesearch/output/29-mini-googlenet\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[INFO] loading CIFAR-10 data...\n","Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 16s 0us/step\n","[INFO] compiling model...\n","[INFO] training network...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/70\n","781/781 [==============================] - 49s 40ms/step - loss: 1.7359 - accuracy: 0.3622 - val_loss: 1.6296 - val_accuracy: 0.4665\n","Epoch 2/70\n","781/781 [==============================] - 31s 39ms/step - loss: 1.1428 - accuracy: 0.5901 - val_loss: 1.1542 - val_accuracy: 0.6181\n","Epoch 3/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.9301 - accuracy: 0.6710 - val_loss: 0.9908 - val_accuracy: 0.6490\n","Epoch 4/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.8021 - accuracy: 0.7193 - val_loss: 0.9512 - val_accuracy: 0.6697\n","Epoch 5/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.7131 - accuracy: 0.7541 - val_loss: 0.7899 - val_accuracy: 0.7398\n","Epoch 6/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.6547 - accuracy: 0.7749 - val_loss: 0.9393 - val_accuracy: 0.7058\n","Epoch 7/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.6130 - accuracy: 0.7890 - val_loss: 0.7649 - val_accuracy: 0.7431\n","Epoch 8/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.5591 - accuracy: 0.8097 - val_loss: 0.7242 - val_accuracy: 0.7599\n","Epoch 9/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.5156 - accuracy: 0.8224 - val_loss: 0.8970 - val_accuracy: 0.7246\n","Epoch 10/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.4868 - accuracy: 0.8340 - val_loss: 0.5576 - val_accuracy: 0.8075\n","Epoch 11/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.4661 - accuracy: 0.8409 - val_loss: 0.6116 - val_accuracy: 0.7926\n","Epoch 12/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.4397 - accuracy: 0.8481 - val_loss: 0.6297 - val_accuracy: 0.8020\n","Epoch 13/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.4141 - accuracy: 0.8587 - val_loss: 0.5049 - val_accuracy: 0.8264\n","Epoch 14/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.3895 - accuracy: 0.8663 - val_loss: 0.5078 - val_accuracy: 0.8330\n","Epoch 15/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.3732 - accuracy: 0.8714 - val_loss: 0.4932 - val_accuracy: 0.8380\n","Epoch 16/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.3557 - accuracy: 0.8812 - val_loss: 0.6139 - val_accuracy: 0.8099\n","Epoch 17/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.3422 - accuracy: 0.8825 - val_loss: 0.7453 - val_accuracy: 0.7872\n","Epoch 18/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.3236 - accuracy: 0.8877 - val_loss: 0.7311 - val_accuracy: 0.7837\n","Epoch 19/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.3150 - accuracy: 0.8905 - val_loss: 0.4698 - val_accuracy: 0.8483\n","Epoch 20/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.3041 - accuracy: 0.8949 - val_loss: 0.4408 - val_accuracy: 0.8589\n","Epoch 21/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2918 - accuracy: 0.8992 - val_loss: 0.5581 - val_accuracy: 0.8282\n","Epoch 22/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2721 - accuracy: 0.9069 - val_loss: 0.4568 - val_accuracy: 0.8523\n","Epoch 23/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2641 - accuracy: 0.9109 - val_loss: 0.4830 - val_accuracy: 0.8479\n","Epoch 24/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2536 - accuracy: 0.9130 - val_loss: 0.3965 - val_accuracy: 0.8697\n","Epoch 25/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2517 - accuracy: 0.9135 - val_loss: 0.4777 - val_accuracy: 0.8480\n","Epoch 26/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2342 - accuracy: 0.9190 - val_loss: 0.4977 - val_accuracy: 0.8495\n","Epoch 27/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2230 - accuracy: 0.9235 - val_loss: 0.5090 - val_accuracy: 0.8431\n","Epoch 28/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2167 - accuracy: 0.9236 - val_loss: 0.4881 - val_accuracy: 0.8487\n","Epoch 29/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.2086 - accuracy: 0.9276 - val_loss: 0.4229 - val_accuracy: 0.8692\n","Epoch 30/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1995 - accuracy: 0.9316 - val_loss: 0.4707 - val_accuracy: 0.8609\n","Epoch 31/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1990 - accuracy: 0.9323 - val_loss: 0.4586 - val_accuracy: 0.8558\n","Epoch 32/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1876 - accuracy: 0.9344 - val_loss: 0.5591 - val_accuracy: 0.8379\n","Epoch 33/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1789 - accuracy: 0.9382 - val_loss: 0.4826 - val_accuracy: 0.8538\n","Epoch 34/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1769 - accuracy: 0.9392 - val_loss: 0.4773 - val_accuracy: 0.8591\n","Epoch 35/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1655 - accuracy: 0.9434 - val_loss: 0.3771 - val_accuracy: 0.8825\n","Epoch 36/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1611 - accuracy: 0.9445 - val_loss: 0.4866 - val_accuracy: 0.8611\n","Epoch 37/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1536 - accuracy: 0.9471 - val_loss: 0.3911 - val_accuracy: 0.8850\n","Epoch 38/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1539 - accuracy: 0.9460 - val_loss: 0.3528 - val_accuracy: 0.8912\n","Epoch 39/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1458 - accuracy: 0.9482 - val_loss: 0.4195 - val_accuracy: 0.8751\n","Epoch 40/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1418 - accuracy: 0.9504 - val_loss: 0.4124 - val_accuracy: 0.8823\n","Epoch 41/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1304 - accuracy: 0.9560 - val_loss: 0.4349 - val_accuracy: 0.8718\n","Epoch 42/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1336 - accuracy: 0.9546 - val_loss: 0.4204 - val_accuracy: 0.8735\n","Epoch 43/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1176 - accuracy: 0.9615 - val_loss: 0.3803 - val_accuracy: 0.8886\n","Epoch 44/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1179 - accuracy: 0.9599 - val_loss: 0.4025 - val_accuracy: 0.8832\n","Epoch 45/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1138 - accuracy: 0.9607 - val_loss: 0.5522 - val_accuracy: 0.8468\n","Epoch 46/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.1087 - accuracy: 0.9633 - val_loss: 0.4134 - val_accuracy: 0.8848\n","Epoch 47/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1063 - accuracy: 0.9634 - val_loss: 0.4315 - val_accuracy: 0.8823\n","Epoch 48/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.1025 - accuracy: 0.9635 - val_loss: 0.4249 - val_accuracy: 0.8873\n","Epoch 49/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0967 - accuracy: 0.9670 - val_loss: 0.4154 - val_accuracy: 0.8862\n","Epoch 50/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0951 - accuracy: 0.9667 - val_loss: 0.3757 - val_accuracy: 0.8909\n","Epoch 51/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: 0.3748 - val_accuracy: 0.8911\n","Epoch 52/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0892 - accuracy: 0.9696 - val_loss: 0.3882 - val_accuracy: 0.8944\n","Epoch 53/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.3856 - val_accuracy: 0.8926\n","Epoch 54/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0801 - accuracy: 0.9737 - val_loss: 0.3896 - val_accuracy: 0.8930\n","Epoch 55/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0804 - accuracy: 0.9730 - val_loss: 0.3882 - val_accuracy: 0.8926\n","Epoch 56/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0726 - accuracy: 0.9760 - val_loss: 0.3641 - val_accuracy: 0.8985\n","Epoch 57/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0724 - accuracy: 0.9762 - val_loss: 0.3786 - val_accuracy: 0.8976\n","Epoch 58/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0693 - accuracy: 0.9767 - val_loss: 0.4107 - val_accuracy: 0.8907\n","Epoch 59/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0667 - accuracy: 0.9778 - val_loss: 0.3974 - val_accuracy: 0.8958\n","Epoch 60/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0647 - accuracy: 0.9792 - val_loss: 0.3727 - val_accuracy: 0.8995\n","Epoch 61/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0657 - accuracy: 0.9780 - val_loss: 0.3847 - val_accuracy: 0.8965\n","Epoch 62/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0588 - accuracy: 0.9817 - val_loss: 0.3726 - val_accuracy: 0.8986\n","Epoch 63/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0561 - accuracy: 0.9817 - val_loss: 0.3770 - val_accuracy: 0.8982\n","Epoch 64/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 0.3727 - val_accuracy: 0.9009\n","Epoch 65/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0532 - accuracy: 0.9824 - val_loss: 0.3587 - val_accuracy: 0.9008\n","Epoch 66/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0537 - accuracy: 0.9824 - val_loss: 0.3643 - val_accuracy: 0.9006\n","Epoch 67/70\n","781/781 [==============================] - 31s 40ms/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 0.3553 - val_accuracy: 0.9037\n","Epoch 68/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0527 - accuracy: 0.9829 - val_loss: 0.3553 - val_accuracy: 0.9038\n","Epoch 69/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.3529 - val_accuracy: 0.9034\n","Epoch 70/70\n","781/781 [==============================] - 31s 39ms/step - loss: 0.0485 - accuracy: 0.9853 - val_loss: 0.3517 - val_accuracy: 0.9045\n","[INFO] serializing network...\n","[INFO] done.\n"],"name":"stdout"}]}]}