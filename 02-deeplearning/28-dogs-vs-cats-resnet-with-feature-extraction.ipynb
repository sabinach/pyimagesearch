{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"28-dogs-vs-cats-resnet-with-feature-extraction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNhJ4djDeUQFkSh5kNghFxe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"odW3GWztwpTP"},"source":["**Use GPU: Runtime -> Change runtime type -> GPU (Hardware Accelerator)**"]},{"cell_type":"markdown","metadata":{"id":"DsUbh5bVwrxZ"},"source":["Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjH-OWedwsEv","executionInfo":{"status":"ok","timestamp":1618893821126,"user_tz":240,"elapsed":508,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"abf184a4-d6fb-494f-bd22-8744a2a8bb45"},"source":["!cat ~/.keras/keras.json"],"execution_count":2,"outputs":[{"output_type":"stream","text":["{\n","    \"epsilon\": 1e-07, \n","    \"floatx\": \"float32\", \n","    \"image_data_format\": \"channels_last\", \n","    \"backend\": \"tensorflow\"\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQWPkRB6lwof","executionInfo":{"status":"ok","timestamp":1618893908143,"user_tz":240,"elapsed":303,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"99417983-f7af-4031-fe2a-e53eff3679d6"},"source":["import keras\n","print(keras.__version__)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2.4.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lf-Kn9CSpG-9"},"source":["HDF5"]},{"cell_type":"code","metadata":{"id":"WE9P8UsbpHIF"},"source":["# import the necessary packages\n","from keras.utils import np_utils\n","import numpy as np\n","import h5py\n","\n","class HDF5DatasetGenerator:\n","    def __init__(self, dbPath, batchSize, preprocessors=None,\n","        aug=None, binarize=True, classes=2):\n","        # store the batch size, preprocessors, and data augmentor,\n","        # whether or not the labels should be binarized, along with\n","        # the total number of classes\n","        self.batchSize = batchSize\n","        self.preprocessors = preprocessors\n","        self.aug = aug\n","        self.binarize = binarize\n","        self.classes = classes\n","\n","        # open the HDF5 database for reading and determine the total\n","        # number of entries in the database\n","        self.db = h5py.File(dbPath)\n","        self.numImages = self.db[\"labels\"].shape[0]\n","\n","    def generator(self, passes=np.inf):\n","        # initialize the epoch count\n","        epochs = 0\n","\n","        # keep looping infinitely -- the model will stop once we have\n","        # reach the desired number of epochs\n","        while epochs < passes:\n","            # loop over the HDF5 dataset\n","            for i in np.arange(0, self.numImages, self.batchSize):\n","                # extract the images and labels from the HDF dataset\n","                images = self.db[\"images\"][i: i + self.batchSize]\n","                labels = self.db[\"labels\"][i: i + self.batchSize]\n","\n","                # check to see if the labels should be binarized\n","                if self.binarize:\n","                    labels = np_utils.to_categorical(labels,\n","                        self.classes)\n","\n","                # check to see if our preprocessors are not None\n","                if self.preprocessors is not None:\n","                    # initialize the list of processed images\n","                    procImages = []\n","\n","                    # loop over the images\n","                    for image in images:\n","                        # loop over the preprocessors and apply each\n","                        # to the image\n","                        for p in self.preprocessors:\n","                            image = p.preprocess(image)\n","\n","                        # update the list of processed images\n","                        procImages.append(image)\n","\n","                    # update the images array to be the processed\n","                    # images\n","                    images = np.array(procImages)\n","\n","                # if the data augmenator exists, apply it\n","                if self.aug is not None:\n","                    (images, labels) = next(self.aug.flow(images,\n","                        labels, batch_size=self.batchSize))\n","\n","                # yield a tuple of images and labels\n","                yield (images, labels)\n","\n","            # increment the total number of epochs\n","            epochs += 1\n","\n","    def close(self):\n","        # close the database\n","        self.db.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qqSwHM7TgXO3"},"source":["Extract Features"]},{"cell_type":"code","metadata":{"id":"9lu5QKKNgWha"},"source":["# import the necessary packages\n","from keras.applications import ResNet50\n","from keras.applications import imagenet_utils\n","from keras.preprocessing.image import img_to_array\n","from keras.preprocessing.image import load_img\n","from sklearn.preprocessing import LabelEncoder\n","from imutils import paths\n","import numpy as np\n","import progressbar\n","import random\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6e74oqFgbdN"},"source":["def extract_features(dataset_filepath, output_filepath, batch_size=16, buffer_size=1000):\n","    # store the batch size in a convenience variable\n","    bs = batch_size\n","\n","    # grab the list of images that we'll be describing then randomly\n","    # shuffle them to allow for easy training and testing splits via\n","    # array slicing during training time\n","    print(\"[INFO] loading images...\")\n","    imagePaths = list(paths.list_images(dataset_filepath))\n","    random.shuffle(imagePaths)\n","\n","    # extract the class labels from the image paths then encode the\n","    # labels\n","    labels = [p.split(os.path.sep)[-1].split(\".\")[0] for p in imagePaths]\n","    le = LabelEncoder()\n","    labels = le.fit_transform(labels)\n","\n","    # load the ResNet50 network\n","    print(\"[INFO] loading network...\")\n","    model = ResNet50(weights=\"imagenet\", include_top=False)\n","\n","    # initialize the HDF5 dataset writer, then store the class label\n","    # names in the dataset\n","    dataset = HDF5DatasetWriter((len(imagePaths), 100352), output_filepath, dataKey=\"features\", bufSize=buffer_size)\n","    dataset.storeClassLabels(le.classes_)\n","\n","    # initialize the progress bar\n","    widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n","    pbar = progressbar.ProgressBar(maxval=len(imagePaths), widgets=widgets).start()\n","\n","    # loop over the images in batches\n","    for i in np.arange(0, len(imagePaths), bs):\n","        # extract the batch of images and labels, then initialize the\n","        # list of actual images that will be passed through the network\n","        # for feature extraction\n","        batchPaths = imagePaths[i:i + bs]\n","        batchLabels = labels[i:i + bs]\n","        batchImages = []\n","\n","        # loop over the images and labels in the current batch\n","        for (j, imagePath) in enumerate(batchPaths):\n","            # load the input image using the Keras helper utility\n","            # while ensuring the image is resized to 224x224 pixels\n","            image = load_img(imagePath, target_size=(224, 224))\n","            image = img_to_array(image)\n","\n","            # preprocess the image by (1) expanding the dimensions and\n","            # (2) subtracting the mean RGB pixel intensity from the\n","            # ImageNet dataset\n","            image = np.expand_dims(image, axis=0)\n","            image = imagenet_utils.preprocess_input(image)\n","\n","            # add the image to the batch\n","            batchImages.append(image)\n","\n","        # pass the images through the network and use the outputs as\n","        # our actual features\n","        batchImages = np.vstack(batchImages)\n","        features = model.predict(batchImages, batch_size=bs)\n","\n","        # reshape the features so that each image is represented by\n","        # a flattened feature vector of the `MaxPooling2D` outputs\n","        features = features.reshape((features.shape[0], 100352))\n","\n","        # add the features and labels to our HDF5 dataset\n","        dataset.add(features, batchLabels)\n","        pbar.update(i)\n","\n","    # close the dataset\n","    dataset.close()\n","    pbar.finish()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yY2xW_knjWsO"},"source":["extract_features(dataset_filepath=\"drive/MyDrive/pyimagesearch/datasets/kaggle-dogs-vs-cats/train\", \n","                 output_filepath=\"drive/MyDrive/pyimagesearch/output/26-kaggle-dogs-vs-cats/hdf5/features.hdf5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-k9rt8NwvGV"},"source":["Train Model"]},{"cell_type":"code","metadata":{"id":"B4VSNB6lwuoV"},"source":["# import the necessary packages\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","import pickle\n","import h5py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKnHmYO_fT8l"},"source":["def train_model(db_filepath, model_filepath, jobs=-1):\n","    # open the HDF5 database for reading then determine the index of\n","    # the training and testing split, provided that this data was\n","    # already shuffled *prior* to writing it to disk\n","    db = h5py.File(db_filepath, \"r\")\n","    i = int(db[\"labels\"].shape[0] * 0.75)\n","\n","    # define the set of parameters that we want to tune then start a\n","    # grid search where we evaluate our model for each value of C\n","    print(\"[INFO] tuning hyperparameters...\")\n","    params = {\"C\": [0.0001, 0.001, 0.01, 0.1, 1.0]}\n","    model = GridSearchCV(LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"), params, cv=3, n_jobs=jobs)\n","    model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n","    print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n","\n","    # generate a classification report for the model\n","    print(\"[INFO] evaluating...\")\n","    preds = model.predict(db[\"features\"][i:])\n","    print(classification_report(db[\"labels\"][i:], preds, target_names=db[\"label_names\"]))\n","\n","    # compute the raw accuracy with extra precision\n","    acc = accuracy_score(db[\"labels\"][i:], preds)\n","    print(\"[INFO] score: {}\".format(acc))\n","\n","    # serialize the model to disk\n","    print(\"[INFO] saving model...\")\n","    f = open(model_filepath, \"wb\")\n","    f.write(pickle.dumps(model.best_estimator_))\n","    f.close()\n","\n","    # close the database\n","    db.close()\n","\n","    print(\"[INFO] done.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CczFJjS3f64N"},"source":["train_model(db_filepath=\"drive/MyDrive/pyimagesearch/output/26-kaggle-dogs-vs-cats/hdf5/features.hdf5\", \n","            model_filepath=\"drive/MyDrive/pyimagesearch/output/26-kaggle-dogs-vs-cats/kaggle-dogs-vs-cats.pickle\")"],"execution_count":null,"outputs":[]}]}