{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg77ubYAcSqn"
   },
   "source": [
    "**Use GPU: Runtime -> Change runtime type -> GPU (Hardware Accelerator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep7Z_g8bcTVq"
   },
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1935,
     "status": "ok",
     "timestamp": 1616895225315,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "DGL7-qyacVEM",
    "outputId": "f3f4d755-fac7-4773-835d-f7f7718e1a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"epsilon\": 1e-07, \n",
      "    \"floatx\": \"float32\", \n",
      "    \"image_data_format\": \"channels_last\", \n",
      "    \"backend\": \"tensorflow\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIUeOZ8KcZCP"
   },
   "source": [
    "Mini-VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2356,
     "status": "ok",
     "timestamp": 1616895226849,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "LJkVmh4UcakM"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1852,
     "status": "ok",
     "timestamp": 1616895226851,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "qR9XyQUYccQw"
   },
   "outputs": [],
   "source": [
    "class MiniVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# first CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEPt0RAmc1IJ"
   },
   "source": [
    "Training Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1616895226852,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "Fu-YGd7Hc2k5"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import BaseLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1616895573446,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "XfOefVxfc5LG"
   },
   "outputs": [],
   "source": [
    "class TrainingMonitor(BaseLogger):\n",
    "    def __init__(self, jsonPath=None, startAt=0):\n",
    "        # store the output path for the figure, the path to the JSON\n",
    "        # serialized file, and the starting epoch\n",
    "        super(TrainingMonitor, self).__init__()\n",
    "        self.jsonPath = jsonPath\n",
    "        self.startAt = startAt\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # initialize the history dictionary\n",
    "        self.H = {}\n",
    "\n",
    "        # if the JSON history path exists, load the training history\n",
    "        if self.jsonPath is not None:\n",
    "            if os.path.exists(self.jsonPath):\n",
    "                self.H = json.loads(open(self.jsonPath).read())\n",
    "\n",
    "                # check to see if a starting epoch was supplied\n",
    "                if self.startAt > 0:\n",
    "                    # loop over the entries in the history log and\n",
    "                    # trim any entries that are past the starting\n",
    "                    # epoch\n",
    "                    for k in self.H.keys():\n",
    "                        self.H[k] = self.H[k][:self.startAt]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # loop over the logs and update the loss, accuracy, etc.\n",
    "        # for the entire training process\n",
    "        for (k, v) in logs.items():\n",
    "            l = self.H.get(k, [])\n",
    "            l.append(float(v))\n",
    "            self.H[k] = l\n",
    "\n",
    "        # check to see if the training history should be serialized\n",
    "        # to file\n",
    "        if self.jsonPath is not None:\n",
    "            f = open(self.jsonPath, \"w\")\n",
    "            f.write(json.dumps(self.H))\n",
    "            f.close()\n",
    "\n",
    "        # ensure at least two epochs have passed before plotting\n",
    "        # (epoch starts at zero)\n",
    "        if len(self.H[\"loss\"]) > 1:\n",
    "            # plot the training loss and accuracy\n",
    "            N = np.arange(0, len(self.H[\"loss\"]))\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n",
    "            plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n",
    "            plt.plot(N, self.H[\"accuracy\"], label=\"train_accuracy\")\n",
    "            plt.plot(N, self.H[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(len(self.H[\"loss\"])))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMJD3SUIcdrE"
   },
   "source": [
    "Train Mini-VGGNet (CIFAR10) w/ Training Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1616895573984,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "OzJKCTdQcwpj"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1616895574392,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "TYHe8_1JcdS1"
   },
   "outputs": [],
   "source": [
    "def train_minivggnet_cifar_with_monitor(jsonPath):\n",
    "    # show information on the process ID\n",
    "    print(\"[INFO process ID: {}\".format(os.getpid()))\n",
    "\n",
    "    # load the training and testing data, then scale it into the\n",
    "    # range [0, 1]\n",
    "    print(\"[INFO] loading CIFAR-10 data...\")\n",
    "    ((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "    trainX = trainX.astype(\"float\") / 255.0\n",
    "    testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    lb = LabelBinarizer()\n",
    "    trainY = lb.fit_transform(trainY)\n",
    "    testY = lb.transform(testY)\n",
    "\n",
    "    # initialize the label names for the CIFAR-10 dataset\n",
    "    labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "    # initialize the SGD optimizer, but without any learning rate decay\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "    model = MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "    # construct the set of callbacks\n",
    "    callbacks = [TrainingMonitor(jsonPath=jsonPath)]\n",
    "\n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=100, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "11zlW4FVHnTJr6k7vhsJFb-UylGW3fGOq"
    },
    "executionInfo": {
     "elapsed": 853298,
     "status": "ok",
     "timestamp": 1616896483241,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "fjflQs1KdE2j",
    "outputId": "a807e8bd-f144-4e53-a571-9295bd3d1944"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_minivggnet_cifar_with_monitor(jsonPath=\"drive/MyDrive/pyimagesearch/output/mini-vggnet-training-monitor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od-JrQXzdF7s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMkDSjH3LaVpKiEqhfYt1wG",
   "collapsed_sections": [],
   "mount_file_id": "10hd_5CbCsW2ZHKYcwqAdgq37RuSS5ru_",
   "name": "15-mini-vggnet-with-training-monitor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
