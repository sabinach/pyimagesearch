{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"21-feature-extraction.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1OF6VfNw4Z8OSwgOMOty-um9L-8YoIqUK","authorship_tag":"ABX9TyP9lUC77OmSCWLfCZf696kW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NU3aQ5L5XPgM"},"source":["**Use GPU: Runtime -> Change runtime type -> GPU (Hardware Accelerator)**"]},{"cell_type":"markdown","metadata":{"id":"FnG7tDkCXG4e"},"source":["Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjypUYB_BkA0","executionInfo":{"status":"ok","timestamp":1618806121297,"user_tz":240,"elapsed":465,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"ede85b5c-a632-4226-b892-28dd867dc540"},"source":["!cat ~/.keras/keras.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{\n","    \"epsilon\": 1e-07, \n","    \"floatx\": \"float32\", \n","    \"image_data_format\": \"channels_last\", \n","    \"backend\": \"tensorflow\"\n","}"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cPo8M3eVCkV5"},"source":["HDF5"]},{"cell_type":"code","metadata":{"id":"bbya2SPXCixD"},"source":["# import the necessary packages\n","import h5py\n","import os\n","\n","class HDF5DatasetWriter:\n","  def __init__(self, dims, outputPath, dataKey=\"images\",\n","    bufSize=1000):\n","    # check to see if the output path exists, and if so, raise\n","    # an exception\n","    if os.path.exists(outputPath):\n","      raise ValueError(\"The supplied `outputPath` already exists and cannot be overwritten. Manually delete the file before continuing.\", outputPath)\n","\n","    # open the HDF5 database for writing and create two datasets:\n","    # one to store the images/features and another to store the\n","    # class labels\n","    self.db = h5py.File(outputPath, \"w\")\n","    self.data = self.db.create_dataset(dataKey, dims, dtype=\"float\")\n","    self.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n","\n","    # store the buffer size, then initialize the buffer itself\n","    # along with the index into the datasets\n","    self.bufSize = bufSize\n","    self.buffer = {\"data\": [], \"labels\": []}\n","    self.idx = 0\n","\n","  def add(self, rows, labels):\n","    # add the rows and labels to the buffer\n","    self.buffer[\"data\"].extend(rows)\n","    self.buffer[\"labels\"].extend(labels)\n","\n","    # check to see if the buffer needs to be flushed to disk\n","    if len(self.buffer[\"data\"]) >= self.bufSize:\n","      self.flush()\n","\n","  def flush(self):\n","    # write the buffers to disk then reset the buffer\n","    i = self.idx + len(self.buffer[\"data\"])\n","    self.data[self.idx:i] = self.buffer[\"data\"]\n","    self.labels[self.idx:i] = self.buffer[\"labels\"]\n","    self.idx = i\n","    self.buffer = {\"data\": [], \"labels\": []}\n","\n","  def storeClassLabels(self, classLabels):\n","    # create a dataset to store the actual class label names,\n","    # then store the class labels\n","    dt = h5py.special_dtype(vlen=str) # `vlen=unicode` for Py2.7\n","    labelSet = self.db.create_dataset(\"label_names\", (len(classLabels),), dtype=dt)\n","    labelSet[:] = classLabels\n","\n","  def close(self):\n","    # check to see if there are any other entries in the buffer\n","    # that need to be flushed to disk\n","    if len(self.buffer[\"data\"]) > 0:\n","        self.flush()\n","\n","    # close the dataset\n","    self.db.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c14lwnaZ6_uk"},"source":["Extract Features (VGG16)"]},{"cell_type":"code","metadata":{"id":"tuLArBq97J70"},"source":["# import the necessary packages\n","from keras.applications import VGG16\n","from keras.applications import imagenet_utils\n","from keras.preprocessing.image import img_to_array\n","from keras.preprocessing.image import load_img\n","from sklearn.preprocessing import LabelEncoder\n","from imutils import paths\n","import numpy as np\n","import progressbar\n","import argparse\n","import random\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hu4VddHG7DX9"},"source":["def extractFeatures_vgg16(dataset_filepath, outputFile_filepath, bs=32, buffer_size=1000):\n","    # grab the list of images that we'll be describing then randomly\n","    # shuffle them to allow for easy training and testing splits via\n","    # array slicing during training time\n","    print(\"[INFO] loading images...\")\n","    imagePaths = list(paths.list_images(dataset_filepath))\n","    random.shuffle(imagePaths)\n","\n","    # extract the class labels from the image paths then encode the\n","    # labels\n","    labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n","    le = LabelEncoder()\n","    labels = le.fit_transform(labels)\n","\n","    # load the VGG16 network\n","    print(\"[INFO] loading network...\")\n","    model = VGG16(weights=\"imagenet\", include_top=False)\n","\n","    # initialize the HDF5 dataset writer, then store the class label\n","    # names in the dataset\n","    dataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7), outputFile_filepath, dataKey=\"features\", bufSize=buffer_size)\n","    dataset.storeClassLabels(le.classes_)\n","\n","    # initialize the progress bar\n","    widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n","    pbar = progressbar.ProgressBar(maxval=len(imagePaths),\n","    widgets=widgets).start()\n","\n","    # loop over the images in patches\n","    for i in np.arange(0, len(imagePaths), bs):\n","        # extract the batch of images and labels, then initialize the\n","        # list of actual images that will be passed through the network\n","        # for feature extraction\n","        batchPaths = imagePaths[i:i + bs]\n","        batchLabels = labels[i:i + bs]\n","        batchImages = []\n","\n","        # loop over the images and labels in the current batch\n","        for (j, imagePath) in enumerate(batchPaths):\n","            # load the input image using the Keras helper utility\n","            # while ensuring the image is resized to 224x224 pixels\n","            image = load_img(imagePath, target_size=(224, 224))\n","            image = img_to_array(image)\n","\n","            # preprocess the image by (1) expanding the dimensions and\n","            # (2) subtracting the mean RGB pixel intensity from the\n","            # ImageNet dataset\n","            image = np.expand_dims(image, axis=0)\n","            image = imagenet_utils.preprocess_input(image)\n","\n","            # add the image to the batch\n","            batchImages.append(image)\n","\n","        # pass the images through the network and use the outputs as\n","        # our actual features\n","        batchImages = np.vstack(batchImages)\n","        features = model.predict(batchImages, batch_size=bs)\n","\n","        # reshape the features so that each image is represented by\n","        # a flattened feature vector of the `MaxPooling2D` outputs\n","        features = features.reshape((features.shape[0], 512 * 7 * 7))\n","\n","        # add the features and labels to our HDF5 dataset\n","        dataset.add(features, batchLabels)\n","        pbar.update(i)\n","\n","    # close the dataset\n","    dataset.close()\n","    pbar.finish()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMs5BY8N7qTc","executionInfo":{"status":"ok","timestamp":1618807107121,"user_tz":240,"elapsed":922018,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"8e889ec9-05cc-4621-fa90-3b7469632cb0"},"source":["extractFeatures_vgg16(dataset_filepath=\"drive/MyDrive/pyimagesearch/datasets/animals\", outputFile_filepath=\"drive/MyDrive/pyimagesearch/output/21-feature-extraction/animals_features.hdf5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] loading images...\n","[INFO] loading network...\n"],"name":"stdout"},{"output_type":"stream","text":["Extracting Features: 100% |####################################| Time:  0:15:21\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"i0MQwxkn9GFb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618810029228,"user_tz":240,"elapsed":3839976,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"da05e346-33c0-4c36-fa78-68a1ab50823a"},"source":["extractFeatures_vgg16(dataset_filepath=\"drive/MyDrive/pyimagesearch/datasets/flowers17\", outputFile_filepath=\"drive/MyDrive/pyimagesearch/output/21-feature-extraction/flowers17_features.hdf5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] loading images...\n","[INFO] loading network...\n"],"name":"stdout"},{"output_type":"stream","text":["Extracting Features: 100% |####################################| Time:  0:06:09\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OB7E8Q-u7KgS"},"source":["Investigating the .hdf5 files (animals)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5s1EIRN_Xy0g","executionInfo":{"status":"ok","timestamp":1618810412157,"user_tz":240,"elapsed":320,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"606b38c6-657e-44da-f326-7bc108ef47fa"},"source":["db = h5py.File(\"drive/MyDrive/pyimagesearch/output/21-feature-extraction/animals_features.hdf5\")\n","print(\"keys: {}\".format(list(db.keys())))\n","print(\"features: {}\".format(db[\"features\"].shape))\n","print(\"labels: {}\".format(db[\"labels\"].shape))\n","print(\"label_names: {}\".format(db[\"label_names\"].shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["keys: ['features', 'label_names', 'labels']\n","features: (3000, 25088)\n","labels: (3000,)\n","label_names: (3,)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"d2vQ92oW7AGM"},"source":["Train Linear Model"]},{"cell_type":"code","metadata":{"id":"Pbmt6mRGXyv1"},"source":["# import the necessary packages\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","import argparse\n","import pickle\n","import h5py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfniX-Y2Xypa"},"source":["def train_linearModel_hdf5(db_filename, model_filename, jobs=-1):\n","    # open the HDF5 database for reading then determine the index of\n","    # the training and testing split, provided that this data was\n","    # already shuffled *prior* to writing it to disk\n","    db = h5py.File(db_filename, \"r\")\n","    i = int(db[\"labels\"].shape[0] * 0.75) # initial 75% of data is training, last 25% is testing\n","\n","    # define the set of parameters that we want to tune then start a\n","    # grid search where we evaluate our model for each value of C\n","    print(\"[INFO] tuning hyperparameters...\")\n","    params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n","    model = GridSearchCV(LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"), params, cv=3, n_jobs=jobs)\n","    model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n","    print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n","\n","    # evaluate the model\n","    print(\"[INFO] evaluating...\")\n","    preds = model.predict(db[\"features\"][i:])\n","    print(classification_report(db[\"labels\"][i:], preds, target_names=db[\"label_names\"]))\n","\n","    # serialize the model to disk\n","    print(\"[INFO] saving model...\")\n","    f = open(model_filename, \"wb\")\n","    f.write(pickle.dumps(model.best_estimator_))\n","    f.close()\n","\n","    # close the database\n","    db.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SAxW52TtZwLN","executionInfo":{"status":"ok","timestamp":1618810546101,"user_tz":240,"elapsed":129358,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"0b110c77-69e4-49e5-b88b-53aa942cba78"},"source":["train_linearModel_hdf5(db_filename=\"drive/MyDrive/pyimagesearch/output/21-feature-extraction/animals_features.hdf5\", model_filename=\"drive/MyDrive/pyimagesearch/output/21-feature-extraction/animals.cpickle\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] tuning hyperparameters...\n","[INFO] best hyperparameters: {'C': 100.0}\n","[INFO] evaluating...\n","              precision    recall  f1-score   support\n","\n","        cats       0.97      0.99      0.98       245\n","        dogs       0.98      0.97      0.98       257\n","       panda       1.00      0.99      1.00       248\n","\n","    accuracy                           0.98       750\n","   macro avg       0.98      0.98      0.98       750\n","weighted avg       0.98      0.98      0.98       750\n","\n","[INFO] saving model...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQRj4svXaGiO","executionInfo":{"status":"ok","timestamp":1618812445417,"user_tz":240,"elapsed":141494,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"bc2859a6-4a91-421f-eb2b-a0383fe08a6d"},"source":["train_linearModel_hdf5(db_filename=\"drive/MyDrive/pyimagesearch/output/21-feature-extraction/flowers17_features.hdf5\", model_filename=\"drive/MyDrive/pyimagesearch/output/21-feature-extraction/flowers17.cpickle\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] tuning hyperparameters...\n","[INFO] best hyperparameters: {'C': 1000.0}\n","[INFO] evaluating...\n","              precision    recall  f1-score   support\n","\n","    bluebell       0.91      1.00      0.95        20\n","   buttercup       0.95      0.88      0.91        24\n","   coltsfoot       1.00      0.84      0.91        19\n","     cowslip       0.62      0.76      0.68        17\n","      crocus       0.88      1.00      0.94        23\n","    daffodil       0.74      0.77      0.76        22\n","       daisy       1.00      0.85      0.92        13\n","   dandelion       0.90      1.00      0.95        19\n","  fritillary       0.96      0.96      0.96        23\n","        iris       1.00      0.88      0.93        16\n","  lilyvalley       0.92      0.96      0.94        24\n","       pansy       1.00      0.85      0.92        13\n","    snowdrop       0.75      0.95      0.84        19\n","   sunflower       1.00      1.00      1.00        26\n","   tigerlily       0.91      0.95      0.93        22\n","       tulip       0.94      0.67      0.78        24\n","  windflower       1.00      0.94      0.97        16\n","\n","    accuracy                           0.90       340\n","   macro avg       0.91      0.90      0.90       340\n","weighted avg       0.91      0.90      0.90       340\n","\n","[INFO] saving model...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GNnidpiyunLG"},"source":[""],"execution_count":null,"outputs":[]}]}