{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtNZ1mr7oIOr"
   },
   "source": [
    "**Use GPU: Runtime -> Change runtime type -> GPU (Hardware Accelerator)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDme-Y0YoIRr"
   },
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1616899203660,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "VreY-VkRoPeV",
    "outputId": "918bf85d-84fc-4ef4-ee93-86e80b2cca41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"epsilon\": 1e-07, \n",
      "    \"floatx\": \"float32\", \n",
      "    \"image_data_format\": \"channels_last\", \n",
      "    \"backend\": \"tensorflow\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0afxKRDeoIUD"
   },
   "source": [
    "Mini-VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1789,
     "status": "ok",
     "timestamp": 1616899205511,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "4zMQKBd4oSDn"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1359,
     "status": "ok",
     "timestamp": 1616899205512,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "rXW8qkj0oSKM"
   },
   "outputs": [],
   "source": [
    "class MiniVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# first CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkTd2w7tpPdi"
   },
   "source": [
    "Train MiniVGGNet w/ Checkpoints (Improvements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1616899206367,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "j0DJL90EpPBe"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1616899206368,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "nu_5S6tysdsH"
   },
   "outputs": [],
   "source": [
    "def train_minivggnet_incr_checkpoints(save_filepath):\n",
    "    # load the training and testing data, then scale it into the\n",
    "    # range [0, 1]\n",
    "    print(\"[INFO] loading CIFAR-10 data...\")\n",
    "    ((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "    trainX = trainX.astype(\"float\") / 255.0\n",
    "    testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    lb = LabelBinarizer()\n",
    "    trainY = lb.fit_transform(trainY)\n",
    "    testY = lb.transform(testY)\n",
    "\n",
    "    # initialize the optimizer and model\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True)\n",
    "    model = MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "    # construct the callback to save only the *best* model to disk\n",
    "    # based on the validation loss\n",
    "    fname = os.path.sep.join([save_filepath, \"minivggnet-weights-{epoch:03d}-{val_loss:.4f}.hdf5\"])\n",
    "    checkpoint = ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "    callbacks = [checkpoint]\n",
    "\n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=40, callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275264,
     "status": "ok",
     "timestamp": 1616899482909,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "kIth20OUsxqs",
    "outputId": "a6f80509-2be5-48c5-8cb8-3e778b9dd1b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/40\n",
      "782/782 - 39s - loss: 1.5947 - accuracy: 0.4643 - val_loss: 1.3486 - val_accuracy: 0.5288\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34858, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-001-1.3486.hdf5\n",
      "Epoch 2/40\n",
      "782/782 - 6s - loss: 1.1347 - accuracy: 0.6023 - val_loss: 0.9045 - val_accuracy: 0.6834\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34858 to 0.90451, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-002-0.9045.hdf5\n",
      "Epoch 3/40\n",
      "782/782 - 6s - loss: 0.9623 - accuracy: 0.6636 - val_loss: 0.8380 - val_accuracy: 0.7046\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.90451 to 0.83800, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-003-0.8380.hdf5\n",
      "Epoch 4/40\n",
      "782/782 - 6s - loss: 0.8544 - accuracy: 0.6995 - val_loss: 0.7380 - val_accuracy: 0.7394\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.83800 to 0.73801, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-004-0.7380.hdf5\n",
      "Epoch 5/40\n",
      "782/782 - 6s - loss: 0.7725 - accuracy: 0.7280 - val_loss: 0.7106 - val_accuracy: 0.7560\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73801 to 0.71063, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-005-0.7106.hdf5\n",
      "Epoch 6/40\n",
      "782/782 - 6s - loss: 0.7211 - accuracy: 0.7468 - val_loss: 0.6996 - val_accuracy: 0.7554\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.71063 to 0.69958, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-006-0.6996.hdf5\n",
      "Epoch 7/40\n",
      "782/782 - 6s - loss: 0.6694 - accuracy: 0.7631 - val_loss: 0.6745 - val_accuracy: 0.7713\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.69958 to 0.67452, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-007-0.6745.hdf5\n",
      "Epoch 8/40\n",
      "782/782 - 6s - loss: 0.6362 - accuracy: 0.7762 - val_loss: 0.6485 - val_accuracy: 0.7771\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.67452 to 0.64847, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-008-0.6485.hdf5\n",
      "Epoch 9/40\n",
      "782/782 - 6s - loss: 0.6005 - accuracy: 0.7886 - val_loss: 0.6622 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.64847\n",
      "Epoch 10/40\n",
      "782/782 - 6s - loss: 0.5676 - accuracy: 0.8008 - val_loss: 0.6288 - val_accuracy: 0.7869\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.64847 to 0.62876, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-010-0.6288.hdf5\n",
      "Epoch 11/40\n",
      "782/782 - 6s - loss: 0.5457 - accuracy: 0.8075 - val_loss: 0.5953 - val_accuracy: 0.7957\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.62876 to 0.59528, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-011-0.5953.hdf5\n",
      "Epoch 12/40\n",
      "782/782 - 6s - loss: 0.5214 - accuracy: 0.8150 - val_loss: 0.5878 - val_accuracy: 0.7985\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.59528 to 0.58784, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-012-0.5878.hdf5\n",
      "Epoch 13/40\n",
      "782/782 - 6s - loss: 0.4973 - accuracy: 0.8253 - val_loss: 0.6350 - val_accuracy: 0.7855\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.58784\n",
      "Epoch 14/40\n",
      "782/782 - 6s - loss: 0.4823 - accuracy: 0.8281 - val_loss: 0.5864 - val_accuracy: 0.8008\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.58784 to 0.58644, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-014-0.5864.hdf5\n",
      "Epoch 15/40\n",
      "782/782 - 6s - loss: 0.4572 - accuracy: 0.8364 - val_loss: 0.5739 - val_accuracy: 0.8079\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.58644 to 0.57386, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-015-0.5739.hdf5\n",
      "Epoch 16/40\n",
      "782/782 - 6s - loss: 0.4433 - accuracy: 0.8427 - val_loss: 0.5902 - val_accuracy: 0.8029\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.57386\n",
      "Epoch 17/40\n",
      "782/782 - 6s - loss: 0.4279 - accuracy: 0.8485 - val_loss: 0.5680 - val_accuracy: 0.8076\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.57386 to 0.56798, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-017-0.5680.hdf5\n",
      "Epoch 18/40\n",
      "782/782 - 6s - loss: 0.4093 - accuracy: 0.8541 - val_loss: 0.5637 - val_accuracy: 0.8114\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.56798 to 0.56371, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-018-0.5637.hdf5\n",
      "Epoch 19/40\n",
      "782/782 - 6s - loss: 0.4021 - accuracy: 0.8556 - val_loss: 0.5631 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.56371 to 0.56314, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-019-0.5631.hdf5\n",
      "Epoch 20/40\n",
      "782/782 - 6s - loss: 0.3877 - accuracy: 0.8602 - val_loss: 0.5526 - val_accuracy: 0.8153\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.56314 to 0.55260, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-020-0.5526.hdf5\n",
      "Epoch 21/40\n",
      "782/782 - 6s - loss: 0.3763 - accuracy: 0.8657 - val_loss: 0.5521 - val_accuracy: 0.8152\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.55260 to 0.55206, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-021-0.5521.hdf5\n",
      "Epoch 22/40\n",
      "782/782 - 6s - loss: 0.3645 - accuracy: 0.8694 - val_loss: 0.5478 - val_accuracy: 0.8180\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.55206 to 0.54776, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-022-0.5478.hdf5\n",
      "Epoch 23/40\n",
      "782/782 - 6s - loss: 0.3576 - accuracy: 0.8727 - val_loss: 0.5506 - val_accuracy: 0.8181\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.54776\n",
      "Epoch 24/40\n",
      "782/782 - 6s - loss: 0.3447 - accuracy: 0.8760 - val_loss: 0.5540 - val_accuracy: 0.8199\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.54776\n",
      "Epoch 25/40\n",
      "782/782 - 6s - loss: 0.3391 - accuracy: 0.8784 - val_loss: 0.5424 - val_accuracy: 0.8228\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.54776 to 0.54235, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-025-0.5424.hdf5\n",
      "Epoch 26/40\n",
      "782/782 - 6s - loss: 0.3285 - accuracy: 0.8818 - val_loss: 0.5588 - val_accuracy: 0.8157\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.54235\n",
      "Epoch 27/40\n",
      "782/782 - 6s - loss: 0.3208 - accuracy: 0.8862 - val_loss: 0.5461 - val_accuracy: 0.8221\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.54235\n",
      "Epoch 28/40\n",
      "782/782 - 6s - loss: 0.3131 - accuracy: 0.8882 - val_loss: 0.5558 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.54235\n",
      "Epoch 29/40\n",
      "782/782 - 6s - loss: 0.3010 - accuracy: 0.8907 - val_loss: 0.5415 - val_accuracy: 0.8262\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.54235 to 0.54147, saving model to drive/MyDrive/pyimagesearch/checkpoints/minivggnet-weights-029-0.5415.hdf5\n",
      "Epoch 30/40\n",
      "782/782 - 6s - loss: 0.2962 - accuracy: 0.8926 - val_loss: 0.5446 - val_accuracy: 0.8264\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.54147\n",
      "Epoch 31/40\n",
      "782/782 - 6s - loss: 0.2927 - accuracy: 0.8949 - val_loss: 0.5686 - val_accuracy: 0.8177\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.54147\n",
      "Epoch 32/40\n",
      "782/782 - 6s - loss: 0.2875 - accuracy: 0.8982 - val_loss: 0.5524 - val_accuracy: 0.8263\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.54147\n",
      "Epoch 33/40\n",
      "782/782 - 6s - loss: 0.2788 - accuracy: 0.9002 - val_loss: 0.5468 - val_accuracy: 0.8247\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.54147\n",
      "Epoch 34/40\n",
      "782/782 - 6s - loss: 0.2701 - accuracy: 0.9030 - val_loss: 0.5479 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.54147\n",
      "Epoch 35/40\n",
      "782/782 - 6s - loss: 0.2671 - accuracy: 0.9032 - val_loss: 0.5421 - val_accuracy: 0.8303\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.54147\n",
      "Epoch 36/40\n",
      "782/782 - 6s - loss: 0.2577 - accuracy: 0.9074 - val_loss: 0.5437 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.54147\n",
      "Epoch 37/40\n",
      "782/782 - 6s - loss: 0.2583 - accuracy: 0.9073 - val_loss: 0.5456 - val_accuracy: 0.8264\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.54147\n",
      "Epoch 38/40\n",
      "782/782 - 6s - loss: 0.2528 - accuracy: 0.9098 - val_loss: 0.5525 - val_accuracy: 0.8297\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.54147\n",
      "Epoch 39/40\n",
      "782/782 - 6s - loss: 0.2467 - accuracy: 0.9115 - val_loss: 0.5477 - val_accuracy: 0.8296\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.54147\n",
      "Epoch 40/40\n",
      "782/782 - 6s - loss: 0.2470 - accuracy: 0.9112 - val_loss: 0.5530 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.54147\n"
     ]
    }
   ],
   "source": [
    "train_minivggnet_incr_checkpoints(save_filepath=\"drive/MyDrive/pyimagesearch/output/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYtBB_GzoIXO"
   },
   "source": [
    "Train MiniVGGNet w/ Checkpoints (Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 252625,
     "status": "ok",
     "timestamp": 1616899482911,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "5X8I-09opQlV"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1616899483825,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "bdN7Eo18tEoN"
   },
   "outputs": [],
   "source": [
    "def train_minivggnet_best_checkpoints(save_filepath):\n",
    "    # load the training and testing data, then scale it into the\n",
    "    # range [0, 1]\n",
    "    print(\"[INFO] loading CIFAR-10 data...\")\n",
    "    ((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "    trainX = trainX.astype(\"float\") / 255.0\n",
    "    testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    lb = LabelBinarizer()\n",
    "    trainY = lb.fit_transform(trainY)\n",
    "    testY = lb.transform(testY)\n",
    "\n",
    "    # initialize the optimizer and model\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True)\n",
    "    model = MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "    # construct the callback to save only the *best* model to disk\n",
    "    # based on the validation loss\n",
    "    checkpoint = ModelCheckpoint(save_filepath, monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "    callbacks = [checkpoint]\n",
    "\n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=40, callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273472,
     "status": "ok",
     "timestamp": 1616899756993,
     "user": {
      "displayName": "Sabina Chen",
      "photoUrl": "",
      "userId": "13519457631091889537"
     },
     "user_tz": 240
    },
    "id": "xdEQFWsCtXHd",
    "outputId": "e18d77f4-81ab-4275-8615-ba9de8e5e5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/40\n",
      "782/782 - 7s - loss: 1.6677 - accuracy: 0.4400 - val_loss: 1.1411 - val_accuracy: 0.5940\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.14105, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 2/40\n",
      "782/782 - 6s - loss: 1.1708 - accuracy: 0.5892 - val_loss: 0.9447 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.14105 to 0.94474, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 3/40\n",
      "782/782 - 6s - loss: 0.9789 - accuracy: 0.6582 - val_loss: 0.8778 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.94474 to 0.87778, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 4/40\n",
      "782/782 - 6s - loss: 0.8691 - accuracy: 0.6974 - val_loss: 0.9610 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.87778\n",
      "Epoch 5/40\n",
      "782/782 - 6s - loss: 0.7974 - accuracy: 0.7187 - val_loss: 0.7960 - val_accuracy: 0.7256\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.87778 to 0.79603, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 6/40\n",
      "782/782 - 6s - loss: 0.7376 - accuracy: 0.7419 - val_loss: 0.6999 - val_accuracy: 0.7547\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.79603 to 0.69989, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 7/40\n",
      "782/782 - 6s - loss: 0.6984 - accuracy: 0.7550 - val_loss: 0.6544 - val_accuracy: 0.7730\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.69989 to 0.65436, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 8/40\n",
      "782/782 - 6s - loss: 0.6569 - accuracy: 0.7662 - val_loss: 0.6740 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.65436\n",
      "Epoch 9/40\n",
      "782/782 - 6s - loss: 0.6161 - accuracy: 0.7844 - val_loss: 0.6276 - val_accuracy: 0.7819\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.65436 to 0.62756, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 10/40\n",
      "782/782 - 6s - loss: 0.5884 - accuracy: 0.7928 - val_loss: 0.6291 - val_accuracy: 0.7825\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.62756\n",
      "Epoch 11/40\n",
      "782/782 - 6s - loss: 0.5640 - accuracy: 0.7998 - val_loss: 0.6043 - val_accuracy: 0.7947\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.62756 to 0.60433, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 12/40\n",
      "782/782 - 6s - loss: 0.5442 - accuracy: 0.8078 - val_loss: 0.5932 - val_accuracy: 0.7963\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.60433 to 0.59317, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 13/40\n",
      "782/782 - 6s - loss: 0.5187 - accuracy: 0.8170 - val_loss: 0.5940 - val_accuracy: 0.7944\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59317\n",
      "Epoch 14/40\n",
      "782/782 - 6s - loss: 0.5008 - accuracy: 0.8228 - val_loss: 0.6146 - val_accuracy: 0.7937\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59317\n",
      "Epoch 15/40\n",
      "782/782 - 6s - loss: 0.4849 - accuracy: 0.8273 - val_loss: 0.5847 - val_accuracy: 0.8010\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.59317 to 0.58473, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 16/40\n",
      "782/782 - 6s - loss: 0.4688 - accuracy: 0.8338 - val_loss: 0.5585 - val_accuracy: 0.8062\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.58473 to 0.55849, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 17/40\n",
      "782/782 - 6s - loss: 0.4492 - accuracy: 0.8406 - val_loss: 0.5642 - val_accuracy: 0.8096\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.55849\n",
      "Epoch 18/40\n",
      "782/782 - 6s - loss: 0.4363 - accuracy: 0.8427 - val_loss: 0.5618 - val_accuracy: 0.8116\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.55849\n",
      "Epoch 19/40\n",
      "782/782 - 6s - loss: 0.4232 - accuracy: 0.8502 - val_loss: 0.5536 - val_accuracy: 0.8110\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.55849 to 0.55357, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 20/40\n",
      "782/782 - 6s - loss: 0.4124 - accuracy: 0.8535 - val_loss: 0.5571 - val_accuracy: 0.8132\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.55357\n",
      "Epoch 21/40\n",
      "782/782 - 6s - loss: 0.4042 - accuracy: 0.8563 - val_loss: 0.5513 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.55357 to 0.55135, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 22/40\n",
      "782/782 - 6s - loss: 0.3827 - accuracy: 0.8620 - val_loss: 0.5590 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.55135\n",
      "Epoch 23/40\n",
      "782/782 - 6s - loss: 0.3777 - accuracy: 0.8648 - val_loss: 0.5596 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.55135\n",
      "Epoch 24/40\n",
      "782/782 - 6s - loss: 0.3672 - accuracy: 0.8692 - val_loss: 0.5441 - val_accuracy: 0.8164\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.55135 to 0.54414, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 25/40\n",
      "782/782 - 6s - loss: 0.3588 - accuracy: 0.8709 - val_loss: 0.6103 - val_accuracy: 0.8033\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.54414\n",
      "Epoch 26/40\n",
      "782/782 - 6s - loss: 0.3488 - accuracy: 0.8756 - val_loss: 0.5505 - val_accuracy: 0.8164\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.54414\n",
      "Epoch 27/40\n",
      "782/782 - 6s - loss: 0.3419 - accuracy: 0.8798 - val_loss: 0.5543 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.54414\n",
      "Epoch 28/40\n",
      "782/782 - 6s - loss: 0.3358 - accuracy: 0.8805 - val_loss: 0.5405 - val_accuracy: 0.8224\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.54414 to 0.54054, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 29/40\n",
      "782/782 - 6s - loss: 0.3255 - accuracy: 0.8829 - val_loss: 0.5512 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.54054\n",
      "Epoch 30/40\n",
      "782/782 - 6s - loss: 0.3152 - accuracy: 0.8869 - val_loss: 0.5453 - val_accuracy: 0.8185\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.54054\n",
      "Epoch 31/40\n",
      "782/782 - 6s - loss: 0.3104 - accuracy: 0.8887 - val_loss: 0.5494 - val_accuracy: 0.8224\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.54054\n",
      "Epoch 32/40\n",
      "782/782 - 6s - loss: 0.3016 - accuracy: 0.8903 - val_loss: 0.5490 - val_accuracy: 0.8180\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.54054\n",
      "Epoch 33/40\n",
      "782/782 - 6s - loss: 0.2988 - accuracy: 0.8937 - val_loss: 0.5580 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.54054\n",
      "Epoch 34/40\n",
      "782/782 - 6s - loss: 0.2899 - accuracy: 0.8963 - val_loss: 0.5531 - val_accuracy: 0.8206\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.54054\n",
      "Epoch 35/40\n",
      "782/782 - 6s - loss: 0.2881 - accuracy: 0.8973 - val_loss: 0.5437 - val_accuracy: 0.8216\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.54054\n",
      "Epoch 36/40\n",
      "782/782 - 6s - loss: 0.2879 - accuracy: 0.8979 - val_loss: 0.5396 - val_accuracy: 0.8246\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.54054 to 0.53959, saving model to drive/MyDrive/pyimagesearch/checkpoints\n",
      "INFO:tensorflow:Assets written to: drive/MyDrive/pyimagesearch/checkpoints/assets\n",
      "Epoch 37/40\n",
      "782/782 - 6s - loss: 0.2789 - accuracy: 0.8999 - val_loss: 0.5677 - val_accuracy: 0.8208\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.53959\n",
      "Epoch 38/40\n",
      "782/782 - 6s - loss: 0.2719 - accuracy: 0.9017 - val_loss: 0.5493 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53959\n",
      "Epoch 39/40\n",
      "782/782 - 6s - loss: 0.2682 - accuracy: 0.9044 - val_loss: 0.5443 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53959\n",
      "Epoch 40/40\n",
      "782/782 - 6s - loss: 0.2564 - accuracy: 0.9076 - val_loss: 0.5463 - val_accuracy: 0.8252\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53959\n"
     ]
    }
   ],
   "source": [
    "train_minivggnet_best_checkpoints(save_filepath=\"drive/MyDrive/pyimagesearch/output/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36xlDKUUtawj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMBdsTVJxI5NNmJN8Ss5i7d",
   "collapsed_sections": [],
   "mount_file_id": "1z5ceaG2bfvMF0JvHDykSl15rWJhV3NLa",
   "name": "16-mini-vggnet-with-checkpoints.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
