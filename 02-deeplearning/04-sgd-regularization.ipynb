{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04-sgd-regularization.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1xodC8EBGxHa09JMFIdbc9IEaqGlVFrHy","authorship_tag":"ABX9TyMV3ki+sPGNYQpkGTSyiM9p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ubjIhyxCOUI1"},"source":["Preprocessing"]},{"cell_type":"code","metadata":{"id":"_NCZF0B5OTSt"},"source":["import numpy as np\n","import cv2\n","import os\n","\n","class SimplePreprocessor:\n","  def __init__(self, width, height, inter=cv2.INTER_AREA):\n","    self.width = width\n","    self.height = height\n","    self.inter = inter\n","\n","  # resize the image to a fixed size, ignoring the aspect ratio\n","  def preprocess(self, image):\n","    return cv2.resize(image, (self.width, self.height), interpolation=self.inter)\n","\n","class SimpleDatasetLoader:\n","    def __init__(self, preprocessors=None):\n","        # store the image preprocessor\n","        self.preprocessors = preprocessors\n","\n","        # if the preprocessors are None, initialize them as an empty list\n","        if self.preprocessors is None:\n","            self.preprocessors = []\n","\n","    def load(self, imagePaths, verbose=-1):\n","        # initialize the list of features and labels\n","        data = []\n","        labels = []\n","\n","        # loop over the input images\n","        for (i, imagePath) in enumerate(imagePaths):\n","            # load the image and extract the class label assuming\n","            # that our path has the following format:\n","            # /path/to/dataset/{class}/{image}.jpg\n","            image = cv2.imread(imagePath)\n","            label = imagePath.split(os.path.sep)[-2]\n","\n","            # check to see if our preprocessors are not None\n","            if self.preprocessors is not None:\n","                # loop over the preprocessors and apply each to\n","                # the image\n","                for p in self.preprocessors:\n","                    image = p.preprocess(image)\n","\n","            # treat our processed image as a \"feature vector\"\n","            # by updating the data list followed by the labels\n","            data.append(image)\n","            labels.append(label)\n","\n","            # show an update every `verbose` images\n","            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n","                print(\"[INFO] processed {}/{}\".format(i + 1,\n","                    len(imagePaths)))\n","\n","        # return a tuple of the data and labels\n","        return (np.array(data), np.array(labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NUVwVpBOYU8"},"source":["SGD"]},{"cell_type":"code","metadata":{"id":"rI5d8rAiOHWi"},"source":["from sklearn.linear_model import SGDClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from imutils import paths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ofcRSfwCOOcn"},"source":["def train_sgd(dataset, epochs=10, alpha=0.01, tol=1e-3):\n","    # grab the list of images paths\n","    print(\"[INFO] loading images...\")\n","    imagePaths = list(paths.list_images(dataset))\n","\n","    # initialize the image preprocessor, load the dataset from disk,\n","    # and reshape the data matrix\n","    sp = SimplePreprocessor(32, 32)\n","    sdl = SimpleDatasetLoader(preprocessors=[sp])\n","    (data, labels) = sdl.load(imagePaths, verbose=500)\n","    data = data.reshape((data.shape[0], 3072))\n","\n","    # encode the labels as integers\n","    le = LabelEncoder()\n","    labels = le.fit_transform(labels)\n","\n","    # partition the data into training and testing splits using 75% of\n","    # the data for training and the remaining 25% for testing\n","    (trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n","\n","    # loop over our set of regularizers\n","    for r in (None, \"l1\", \"l2\"):\n","        # train a SGD classifier using a softmax loss function and the\n","        # specified regularization function for 10 epochs\n","        print(\"[INFO] training model with `{}` penalty\".format(r))\n","        model = SGDClassifier(loss=\"log\", penalty=r, max_iter=epochs,\n","            learning_rate=\"constant\", tol=tol, eta0=alpha, random_state=42)\n","        model.fit(trainX, trainY)\n","\n","        # evaluate the classifier\n","        acc = model.score(testX, testY)\n","        print(\"[INFO] `{}` penalty accuracy: {:.2f}%\".format(r, acc * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPkilG8POk8u","executionInfo":{"status":"ok","timestamp":1616741100907,"user_tz":240,"elapsed":441124,"user":{"displayName":"Sabina Chen","photoUrl":"","userId":"13519457631091889537"}},"outputId":"e9382861-c307-47f7-a6ee-531864265d93"},"source":["train_sgd(\"drive/MyDrive/pyimagesearch/datasets/animals\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[INFO] loading images...\n","[INFO] processed 500/3000\n","[INFO] processed 1000/3000\n","[INFO] processed 1500/3000\n","[INFO] processed 2000/3000\n","[INFO] processed 2500/3000\n","[INFO] processed 3000/3000\n","[INFO] training model with `None` penalty\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[INFO] `None` penalty accuracy: 55.47%\n","[INFO] training model with `l1` penalty\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[INFO] `l1` penalty accuracy: 53.07%\n","[INFO] training model with `l2` penalty\n","[INFO] `l2` penalty accuracy: 47.60%\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  ConvergenceWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"IcRxD6myOpzY"},"source":[""],"execution_count":null,"outputs":[]}]}