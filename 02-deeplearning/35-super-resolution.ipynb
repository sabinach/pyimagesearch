{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"35-super-resolution.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1wU1iRj_ocUc9HO4SPp0VfZp6g_WSruxo","authorship_tag":"ABX9TyOd7HRvg1kt6jNo3XGKnOVz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4smTrz_o6c3G"},"source":["**Use GPU: Runtime -> Change runtime type -> GPU (Hardware Accelerator)**"]},{"cell_type":"markdown","metadata":{"id":"B6BgzWr46fec"},"source":["Setup"]},{"cell_type":"code","metadata":{"id":"riNdUYd76c-_"},"source":["!cat ~/.keras/keras.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHtEhVHD6gSg"},"source":["import keras\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jCWuEY816dEd"},"source":["Config"]},{"cell_type":"code","metadata":{"id":"Vv7vSspw6dKz"},"source":["# import the necessary packages\n","import os\n","\n","# define the path to the input images we will be using to build the\n","# training crops\n","INPUT_IMAGES = \"drive/MyDrive/pyimagesearch/datasets/ukbench100\"\n","\n","# define the path to the temporary output directories\n","BASE_OUTPUT = \"drive/MyDrive/pyimagesearch/output/35-super-resolution\"\n","IMAGES = os.path.sep.join([BASE_OUTPUT, \"images\"])\n","LABELS = os.path.sep.join([BASE_OUTPUT, \"labels\"])\n","\n","# define the path to the HDF5 files\n","INPUTS_DB = os.path.sep.join([BASE_OUTPUT, \"inputs.hdf5\"])\n","OUTPUTS_DB = os.path.sep.join([BASE_OUTPUT, \"outputs.hdf5\"])\n","\n","# define the path to the output model file and the plot file\n","MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"srcnn.model\"])\n","PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n","\n","# initialize the batch size and number of epochs for training\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 10\n","\n","# initialize the scale (the factor in which we want to learn how to\n","# enlarge images by) along with the input width and height dimensions\n","# to our SRCNN\n","SCALE = 2.0\n","INPUT_DIM = 33\n","\n","# the label size should be the output spatial dimensions of the SRCNN\n","# while our padding ensures we properly crop the label ROI\n","LABEL_SIZE = 21\n","PAD = int((INPUT_DIM - LABEL_SIZE) / 2.0)\n","\n","# the stride controls the step size of our sliding window\n","STRIDE = 14"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fH5f79ne6dQ9"},"source":["HDF5 Dataset Writer"]},{"cell_type":"code","metadata":{"id":"SWdsrz376dWf"},"source":["# import the necessary packages\n","import h5py\n","import os\n","\n","class HDF5DatasetWriter:\n","\tdef __init__(self, dims, outputPath, dataKey=\"images\",\n","\t\tbufSize=1000):\n","\t\t# check to see if the output path exists, and if so, raise\n","\t\t# an exception\n","\t\tif os.path.exists(outputPath):\n","\t\t\traise ValueError(\"The supplied `outputPath` already \"\n","\t\t\t\t\"exists and cannot be overwritten. Manually delete \"\n","\t\t\t\t\"the file before continuing.\", outputPath)\n","\n","\t\t# open the HDF5 database for writing and create two datasets:\n","\t\t# one to store the images/features and another to store the\n","\t\t# class labels\n","\t\tself.db = h5py.File(outputPath, \"w\")\n","\t\tself.data = self.db.create_dataset(dataKey, dims, dtype=\"float\")\n","\t\tself.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n","\n","\t\t# store the buffer size, then initialize the buffer itself\n","\t\t# along with the index into the datasets\n","\t\tself.bufSize = bufSize\n","\t\tself.buffer = {\"data\": [], \"labels\": []}\n","\t\tself.idx = 0\n","\n","\tdef add(self, rows, labels):\n","\t\t# add the rows and labels to the buffer\n","\t\tself.buffer[\"data\"].extend(rows)\n","\t\tself.buffer[\"labels\"].extend(labels)\n","\n","\t\t# check to see if the buffer needs to be flushed to disk\n","\t\tif len(self.buffer[\"data\"]) >= self.bufSize:\n","\t\t\tself.flush()\n","\n","\tdef flush(self):\n","\t\t# write the buffers to disk then reset the buffer\n","\t\ti = self.idx + len(self.buffer[\"data\"])\n","\t\tself.data[self.idx:i] = self.buffer[\"data\"]\n","\t\tself.labels[self.idx:i] = self.buffer[\"labels\"]\n","\t\tself.idx = i\n","\t\tself.buffer = {\"data\": [], \"labels\": []}\n","\n","\tdef storeClassLabels(self, classLabels):\n","\t\t# create a dataset to store the actual class label names,\n","\t\t# then store the class labels\n","\t\tdt = h5py.special_dtype(vlen=str) # `vlen=unicode` for Py2.7\n","\t\tlabelSet = self.db.create_dataset(\"label_names\", (len(classLabels),), dtype=dt)\n","\t\tlabelSet[:] = classLabels\n","\n","\tdef close(self):\n","\t\t# check to see if there are any other entries in the buffer\n","\t\t# that need to be flushed to disk\n","\t\tif len(self.buffer[\"data\"]) > 0:\n","\t\t\tself.flush()\n","\n","\t\t# close the dataset\n","\t\tself.db.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZW-idvY6dci"},"source":["Build Dataset"]},{"cell_type":"code","metadata":{"id":"PCJ4zl9v6dhj"},"source":["# import the necessary packages\n","from imutils import paths\n","from scipy import misc\n","import shutil\n","import random\n","import cv2\n","import os\n","\n","from PIL import Image\n","import numpy as np\n","\n","# if the output directories do not exist, create them\n","for p in [IMAGES, LABELS]:\n","    if not os.path.exists(p):\n","        os.makedirs(p)\n","\n","# grab the image paths and initialize the total number of crops\n","# processed\n","print(\"[INFO] creating temporary images...\")\n","imagePaths = list(paths.list_images(INPUT_IMAGES))\n","random.shuffle(imagePaths)\n","total = 0\n","\n","# loop over the image paths\n","for imagePath in imagePaths:\n","    # load the input image\n","    image = cv2.imread(imagePath)\n","\n","    # grab the dimensions of the input image and crop the image such\n","    # that it tiles nicely when we generate the training data +\n","    # labels\n","    (h, w) = image.shape[:2]\n","    w -= int(w % SCALE)\n","    h -= int(h % SCALE)\n","    image = image[0:h, 0:w]\n","\n","    # to generate our training images we first need to downscale the\n","    # image by the scale factor...and then upscale it back to the\n","    # original size -- this will process allows us to generate low\n","    # resolution inputs that we'll then learn to reconstruct the high\n","    # resolution versions from\n","\n","    scaled = misc.imresize(image, 1.0 / SCALE, interp=\"bicubic\")\n","    scaled = misc.imresize(scaled, SCALE / 1.0, interp=\"bicubic\")\n","\n","    # slide a window from left-to-right and top-to-bottom\n","    for y in range(0, h - INPUT_DIM + 1, STRIDE):\n","        for x in range(0, w - INPUT_DIM + 1, STRIDE):\n","            # crop output the `INPUT_DIM x INPUT_DIM` ROI from our\n","            # scaled image -- this ROI will serve as the input to our network\n","            crop = scaled[y:y + INPUT_DIM, x:x + INPUT_DIM]\n","\n","            # crop out the `LABEL_SIZE x LABEL_SIZE` ROI from our\n","            # original image -- this ROI will be the target output\n","            # from our network\n","            target = image[\n","                y + PAD:y + PAD + LABEL_SIZE,\n","                x + PAD:x + PAD + LABEL_SIZE]\n","\n","            # construct the crop and target output image paths\n","            cropPath = os.path.sep.join([IMAGES, \"{}.png\".format(total)])\n","            targetPath = os.path.sep.join([LABELS, \"{}.png\".format(total)])\n","\n","            # write the images to disk\n","            cv2.imwrite(cropPath, crop)\n","            cv2.imwrite(targetPath, target)\n","\n","            # increment the crop total\n","            total += 1\n","\n","# grab the paths to the images\n","print(\"[INFO] building HDF5 datasets...\")\n","inputPaths = sorted(list(paths.list_images(IMAGES)))\n","outputPaths = sorted(list(paths.list_images(LABELS)))\n","\n","# initialize the HDF5 datasets\n","inputWriter = HDF5DatasetWriter((len(inputPaths), INPUT_DIM, INPUT_DIM, 3), INPUTS_DB)\n","outputWriter = HDF5DatasetWriter((len(outputPaths), LABEL_SIZE, LABEL_SIZE, 3), OUTPUTS_DB)\n","\n","# loop over the images\n","for (inputPath, outputPath) in zip(inputPaths, outputPaths):\n","    # load the two images and add them to their respective datasets\n","    inputImage = cv2.imread(inputPath)\n","    outputImage = cv2.imread(outputPath)\n","    inputWriter.add([inputImage], [-1])\n","    outputWriter.add([outputImage], [-1])\n","\n","# close the HDF5 datasets\n","inputWriter.close()\n","outputWriter.close()\n","\n","# delete the temporary output directories\n","print(\"[INFO] cleaning up...\")\n","shutil.rmtree(IMAGES)\n","shutil.rmtree(LABELS)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zI-q1gXNACuY"},"source":["SRCNN"]},{"cell_type":"code","metadata":{"id":"a7FKqBUdAC4C"},"source":["# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.core import Activation\n","from keras import backend as K\n","\n","class SRCNN:\n","\t@staticmethod\n","\tdef build(width, height, depth):\n","\t\t# initialize the model\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\n","\t\t# the entire SRCNN architecture consists of three CONV =>\n","\t\t# RELU layers with *no* zero-padding\n","\t\tmodel.add(Conv2D(64, (9, 9), kernel_initializer=\"he_normal\",\n","\t\t\tinput_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Conv2D(32, (1, 1), kernel_initializer=\"he_normal\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Conv2D(depth, (5, 5),\n","\t\t\tkernel_initializer=\"he_normal\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fQsu-Tt3BT_8"},"source":["HDF5 Dataset Generator"]},{"cell_type":"code","metadata":{"id":"mZC2fSgHBUJ1"},"source":["# import the necessary packages\n","from keras.utils import np_utils\n","import numpy as np\n","import h5py\n","\n","class HDF5DatasetGenerator:\n","    def __init__(self, dbPath, batchSize, preprocessors=None,\n","        aug=None, binarize=True, classes=2):\n","        # store the batch size, preprocessors, and data augmentor,\n","        # whether or not the labels should be binarized, along with\n","        # the total number of classes\n","        self.batchSize = batchSize\n","        self.preprocessors = preprocessors\n","        self.aug = aug\n","        self.binarize = binarize\n","        self.classes = classes\n","\n","        # open the HDF5 database for reading and determine the total\n","        # number of entries in the database\n","        self.db = h5py.File(dbPath)\n","        self.numImages = self.db[\"labels\"].shape[0]\n","\n","    def generator(self, passes=np.inf):\n","        # initialize the epoch count\n","        epochs = 0\n","\n","        # keep looping infinitely -- the model will stop once we have\n","        # reach the desired number of epochs\n","        while epochs < passes:\n","            # loop over the HDF5 dataset\n","            for i in np.arange(0, self.numImages, self.batchSize):\n","                # extract the images and labels from the HDF dataset\n","                images = self.db[\"images\"][i: i + self.batchSize]\n","                labels = self.db[\"labels\"][i: i + self.batchSize]\n","\n","                # check to see if the labels should be binarized\n","                if self.binarize:\n","                    labels = np_utils.to_categorical(labels,\n","                        self.classes)\n","\n","                # check to see if our preprocessors are not None\n","                if self.preprocessors is not None:\n","                    # initialize the list of processed images\n","                    procImages = []\n","\n","                    # loop over the images\n","                    for image in images:\n","                        # loop over the preprocessors and apply each\n","                        # to the image\n","                        for p in self.preprocessors:\n","                            image = p.preprocess(image)\n","\n","                        # update the list of processed images\n","                        procImages.append(image)\n","\n","                    # update the images array to be the processed\n","                    # images\n","                    images = np.array(procImages)\n","\n","                # if the data augmenator exists, apply it\n","                if self.aug is not None:\n","                    (images, labels) = next(self.aug.flow(images,\n","                        labels, batch_size=self.batchSize))\n","\n","                # yield a tuple of images and labels\n","                yield (images, labels)\n","\n","            # increment the total number of epochs\n","            epochs += 1\n","\n","    def close(self):\n","        # close the database\n","        self.db.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hu7KeiXNBA9-"},"source":["Train"]},{"cell_type":"code","metadata":{"id":"RWe3uFkWBBFp"},"source":["# import the necessary packages\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def super_res_generator(inputDataGen, targetDataGen):\n","\t# start an infinite loop for the training data\n","\twhile True:\n","\t\t# grab the next input images and target outputs, discarding\n","\t\t# the class labels (which are irrelevant)\n","\t\tinputData = next(inputDataGen)[0]\n","\t\ttargetData = next(targetDataGen)[0]\n","\n","\t\t# yield a tuple of the input data and target data\n","\t\tyield (inputData, targetData)\n","\n","# initialize the input images and target output images generators\n","inputs = HDF5DatasetGenerator(INPUTS_DB, BATCH_SIZE)\n","targets = HDF5DatasetGenerator(OUTPUTS_DB, BATCH_SIZE)\n","\n","# initialize the model and optimizer\n","print(\"[INFO] compiling model...\")\n","opt = Adam(lr=0.001, decay=0.001 / NUM_EPOCHS)\n","model = SRCNN.build(width=INPUT_DIM, height=INPUT_DIM, depth=3)\n","model.compile(loss=\"mse\", optimizer=opt)\n","\n","# train the model using our generators\n","H = model.fit_generator(\n","\tsuper_res_generator(inputs.generator(), targets.generator()),\n","\tsteps_per_epoch=inputs.numImages // BATCH_SIZE,\n","\tepochs=NUM_EPOCHS, verbose=1)\n","\n","# save the model to file\n","print(\"[INFO] serializing model...\")\n","model.save(MODEL_PATH, overwrite=True)\n","\n","# plot the training loss\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"loss\"], label=\"loss\")\n","plt.title(\"Loss on super resolution training\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.savefig(PLOT_PATH)\n","\n","# close the HDF5 datasets\n","inputs.close()\n","targets.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbpY72lYAC_e"},"source":["Resize"]},{"cell_type":"code","metadata":{"id":"rcdnYYfPADGQ"},"source":["# import the necessary packages\n","from keras.models import load_model\n","from scipy import misc\n","import numpy as np\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nx--rchxADU9"},"source":["def resize(image_filepath, baseline_filepath, output_filepath):\n","    # load the pre-trained model\n","    print(\"[INFO] loading model...\")\n","    model = load_model(MODEL_PATH)\n","\n","    # load the input image, then grab the dimensions of the input image\n","    # and crop the image such that it tiles nicely\n","    print(\"[INFO] generating image...\")\n","    image = cv2.imread(image_filepath)\n","    (h, w) = image.shape[:2]\n","    w -= int(w % SCALE)\n","    h -= int(h % SCALE)\n","    image = image[0:h, 0:w]\n","\n","    # resize the input image using bicubic interpolation then write the\n","    # baseline image to disk\n","    scaled = misc.imresize(image, SCALE / 1.0, interp=\"bicubic\")\n","    cv2.imwrite(baseline_filepath, scaled)\n","\n","    # allocate memory for the output image\n","    output = np.zeros(scaled.shape)\n","    (h, w) = output.shape[:2]\n","\n","    # slide a window from left-to-right and top-to-bottom\n","    for y in range(0, h - INPUT_DIM + 1, LABEL_SIZE):\n","        for x in range(0, w - INPUT_DIM + 1, LABEL_SIZE):\n","            # crop ROI from our scaled image\n","            crop = scaled[y:y + INPUT_DIM, x:x + INPUT_DIM]\n","\n","            # make a prediction on the crop and store it in our output\n","            # image\n","            P = model.predict(np.expand_dims(crop, axis=0))\n","            P = P.reshape((LABEL_SIZE, LABEL_SIZE, 3))\n","            output[y + PAD:y + PAD + LABEL_SIZE,\n","                x + PAD:x + PAD + LABEL_SIZE] = P\n","\n","    # remove any of the black borders in the output image caused by the\n","    # padding, then clip any values that fall outside the range [0, 255]\n","    output = output[PAD:h - ((h % INPUT_DIM) + PAD), PAD:w - ((w % INPUT_DIM) + PAD)]\n","    output = np.clip(output, 0, 255).astype(\"uint8\")\n","\n","    # write the output image to disk\n","    cv2.imwrite(output_filepath, output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kmErq6z2BgnP"},"source":["resize(image_filepath=\"drive/MyDrive/pyimagesearch/datasets/jemma.png\", \n","       baseline_filepath=\"drive/MyDrive/pyimagesearch/datasets/baseline.png\", \n","       output_filepath=\"drive/MyDrive/pyimagesearch/output/35-super-resolution.png\")"],"execution_count":null,"outputs":[]}]}